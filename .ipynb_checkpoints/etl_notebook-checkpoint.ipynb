{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4ae545c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\matth\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\matth\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\matth\\anaconda3\\lib\\site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\matth\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\matth\\anaconda3\\lib\\site-packages (from requests) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\matth\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\matth\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\matth\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\matth\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\matth\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\matth\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\matth\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install requests python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "371b422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb51a8f0",
   "metadata": {},
   "source": [
    "# EXTRACT\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6729f3",
   "metadata": {},
   "source": [
    "loading environment variables (API key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e13260d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_env_api():\n",
    "    \n",
    "    # load envrionment variables from the .env file\n",
    "    load_dotenv()\n",
    "\n",
    "    # get the API key from the .env file\n",
    "    api_key =os.getenv(\"API_KEY\")\n",
    "    return api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f3de73",
   "metadata": {},
   "source": [
    "load list of cities to query the API about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9401d4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_env_cities():\n",
    "    \n",
    "    # load envrionment variables from the .env file\n",
    "    load_dotenv()\n",
    "    \n",
    "    # get the list of cities from the .env file\n",
    "    cities_str = os.getenv(\"CITIES\")\n",
    "    cities = cities_str.split(\";\")\n",
    "    return cities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6069126",
   "metadata": {},
   "source": [
    "getting latitude and longitude encodings for cities (list of cities in config file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3d933c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function for getting lat & long encoding of cities\n",
    "def encoding(api_key, cities):\n",
    "    \n",
    "    # Geocoding API endpoint\n",
    "    geocoding_url = \"http://api.openweathermap.org/data/2.5/weather\"\n",
    "\n",
    "    # create dataframe to store encodings\n",
    "    encodings = pd.DataFrame(columns=['name', 'latitude', 'longitude'])\n",
    "    \n",
    "    # Loop through the cities and get their lat, lon\n",
    "    for city in cities:\n",
    "        # Send GET request to the OpenWeatherMap Geocoding API\n",
    "        response = requests.get(geocoding_url, params={\n",
    "            'q': city,\n",
    "            'appid': api_key\n",
    "        })\n",
    "\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            lat = data['coord']['lat']\n",
    "            lon = data['coord']['lon']\n",
    "            print(f\"City: {city} - Latitude: {lat}, Longitude: {lon}\")\n",
    "            new_row = pd.DataFrame({\"name\": [city], \"latitude\": [lat], \"longitude\": [lon]})\n",
    "            encodings = pd.concat([encodings, new_row], ignore_index=True)\n",
    "        else:\n",
    "            print(f\"Failed to get data for {city}\")\n",
    "            \n",
    "    return encodings;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "83c924b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## write the city encodings to the config file\n",
    "def encodings_to_config(encodings):\n",
    "    \n",
    "    # Convert the DataFrame to the desired dictionary format\n",
    "    config_data = {\n",
    "        \"cities\": encodings.to_dict(orient=\"records\")  # Convert rows to list of dictionaries\n",
    "    }\n",
    "\n",
    "    # Write the dictionary to a JSON file\n",
    "    with open('cities_config.json', 'w') as json_file:\n",
    "        json.dump(config_data, json_file, indent=4)\n",
    "\n",
    "    print(\"Data has been written to cities_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b5b5328c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: Denver,CO,USA - Latitude: 39.7392, Longitude: -104.9847\n",
      "City: Austin,TX,USA - Latitude: 30.2711, Longitude: -97.7437\n",
      "City: Stuttgart,DE - Latitude: 48.7823, Longitude: 9.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_29864\\1725295058.py:25: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  encodings = pd.concat([encodings, new_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to cities_config.json\n"
     ]
    }
   ],
   "source": [
    "api_key = load_env_api()\n",
    "cities = load_env_cities()\n",
    "encodings = encoding(api_key, cities)\n",
    "encodings_to_config(encodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd26f1c",
   "metadata": {},
   "source": [
    "# API Weather Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1dc5e0",
   "metadata": {},
   "source": [
    "function to execute the API call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bb4364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# api call to get the current weather \n",
    "def get_weather(api_key, city, lat, lon, exclude='minutely,daily,hourly', units='imperial', lang='en'):\n",
    "    # Build the base URL for the OneCall API\n",
    "    url = f\"https://api.openweathermap.org/data/3.0/onecall\"\n",
    "    \n",
    "    # Prepare the parameters for the API call\n",
    "    params = {\n",
    "        'lat': lat,\n",
    "        'lon': lon,\n",
    "        'appid': api_key,\n",
    "        'units': units,  # 'imperial' for Fahrenheit, 'metric' for Celsius\n",
    "        'lang': lang      # Language for the response\n",
    "    }\n",
    "    \n",
    "    # Add the 'exclude' parameter if it's provided\n",
    "    if exclude:\n",
    "        params['exclude'] = exclude\n",
    "    \n",
    "    # Make the API request\n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        # Print or process the data\n",
    "        data['City']=city\n",
    "        print(data)\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c18f49b",
   "metadata": {},
   "source": [
    "function to run the API call based upon cities in config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49ebf24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lat': 39.7392, 'lon': -104.9847, 'timezone': 'America/Denver', 'timezone_offset': -25200, 'current': {'dt': 1739872951, 'sunrise': 1739886501, 'sunset': 1739925578, 'temp': 12.61, 'feels_like': 3.96, 'pressure': 1022, 'humidity': 83, 'dew_point': 8.89, 'uvi': 0, 'clouds': 100, 'visibility': 10000, 'wind_speed': 5.28, 'wind_deg': 29, 'wind_gust': 4.21, 'weather': [{'id': 804, 'main': 'Clouds', 'description': 'overcast clouds', 'icon': '04n'}]}, 'City': 'Denver,CO,USA'}\n",
      "{'lat': 30.2711, 'lon': -97.7437, 'timezone': 'America/Chicago', 'timezone_offset': -21600, 'current': {'dt': 1739872951, 'sunrise': 1739884097, 'sunset': 1739924506, 'temp': 54.7, 'feels_like': 53.96, 'pressure': 1015, 'humidity': 87, 'dew_point': 50.92, 'uvi': 0, 'clouds': 100, 'visibility': 10000, 'wind_speed': 1.99, 'wind_deg': 104, 'wind_gust': 5.01, 'weather': [{'id': 804, 'main': 'Clouds', 'description': 'overcast clouds', 'icon': '04n'}]}, 'alerts': [{'sender_name': 'NWS Austin/San Antonio TX', 'event': 'Cold Weather Advisory', 'start': 1739944800, 'end': 1739988000, 'description': '* WHAT...For the Cold Weather Advisory, very cold wind chills as low\\nas 3 above expected. For the Extreme Cold Watch, dangerously cold\\nwind chills as low as 6 above possible.\\n\\n* WHERE...A portion of south central Texas.\\n\\n* WHEN...For the Cold Weather Advisory, from midnight tonight to\\nnoon CST Wednesday. For the Extreme Cold Watch, from late\\nWednesday night through Thursday morning.\\n\\n* IMPACTS...Frostbite and hypothermia will occur if unprotected skin\\nis exposed to these temperatures.', 'tags': ['Other dangers']}, {'sender_name': 'NWS Austin/San Antonio TX', 'event': 'Extreme Cold Watch', 'start': 1740031200, 'end': 1740074400, 'description': '* WHAT...For the Cold Weather Advisory, very cold wind chills as low\\nas 3 above expected. For the Extreme Cold Watch, dangerously cold\\nwind chills as low as 6 above possible.\\n\\n* WHERE...A portion of south central Texas.\\n\\n* WHEN...For the Cold Weather Advisory, from midnight tonight to\\nnoon CST Wednesday. For the Extreme Cold Watch, from late\\nWednesday night through Thursday morning.\\n\\n* IMPACTS...Frostbite and hypothermia will occur if unprotected skin\\nis exposed to these temperatures.', 'tags': ['Other dangers']}], 'City': 'Austin,TX,USA'}\n",
      "{'lat': 48.7823, 'lon': 9.177, 'timezone': 'Europe/Berlin', 'timezone_offset': 3600, 'current': {'dt': 1739872951, 'sunrise': 1739859971, 'sunset': 1739897313, 'temp': 32.72, 'feels_like': 24.44, 'pressure': 1025, 'humidity': 69, 'dew_point': 24.64, 'uvi': 1.46, 'clouds': 0, 'visibility': 10000, 'wind_speed': 10.36, 'wind_deg': 70, 'weather': [{'id': 800, 'main': 'Clear', 'description': 'clear sky', 'icon': '01d'}]}, 'alerts': [{'sender_name': 'Deutscher Wetterdienst', 'event': 'frost', 'start': 1739811600, 'end': 1739876400, 'description': 'There is a risk of frost (level 1 of 2).\\nMinimum temperature: -4 - -9 °C; near surface: > -12 °C', 'tags': ['Extreme low temperature']}], 'City': 'Stuttgart,DE'}\n"
     ]
    }
   ],
   "source": [
    "def city_weather_data_extraction():\n",
    "    # Step 1: Load the config file\n",
    "    with open('cities_config.json', 'r') as f:\n",
    "        config_data = json.load(f)\n",
    "\n",
    "    weather_data = []\n",
    "\n",
    "    # Step 2: Loop through each city and use the data for API requests\n",
    "    for city in config_data['cities']:\n",
    "        latitude = city['latitude']\n",
    "        longitude = city['longitude']\n",
    "        city_name = city['name']\n",
    "\n",
    "        weather_data.append(get_weather(api_key, city_name, latitude, longitude))\n",
    "        \n",
    "    return weather_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fab3aaf",
   "metadata": {},
   "source": [
    "writing the extracted data to the raw_weather_data.json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e7497c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to data/raw_weather_data.json\n"
     ]
    }
   ],
   "source": [
    "def write_raw_data(weather_data):\n",
    "    # File path within the \"data\" folder\n",
    "    file_path = 'data/raw_weather_data.json'\n",
    "\n",
    "    # Check if the file exists to decide whether to append or create new\n",
    "    if os.path.exists(file_path):\n",
    "        # If the file exists, load the existing data, then append new data\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            existing_data = json.load(json_file)\n",
    "            existing_data.extend(weather_data)\n",
    "\n",
    "        # Append to the file\n",
    "        with open(file_path, 'w') as json_file:\n",
    "            json.dump(existing_data, json_file, indent=4)\n",
    "    else:\n",
    "        # If the file doesn't exist, create it and write the new data\n",
    "        with open(file_path, 'w') as json_file:\n",
    "            json.dump(weather_data, json_file, indent=4)\n",
    "\n",
    "    print(f\"Data saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5617cd6",
   "metadata": {},
   "source": [
    "executing the api calls & writing to the file functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d6c738",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = city_weather_data_extraction()\n",
    "write_raw_data(weather_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2604f14b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a31a64c",
   "metadata": {},
   "source": [
    "# Transform:\n",
    "clean the weather data \n",
    "write it to a clean_data and db_ready csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6082fd36",
   "metadata": {},
   "source": [
    "reading the raw data from the raw_weather_data.json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51119c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_data():\n",
    "    # File path within the \"data\" folder\n",
    "    file_path = 'data/raw_weather_data.json'\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: the file '{file_path}' does not exist\")\n",
    "        return None\n",
    "    except json.jSONDecodeError:\n",
    "        print(f\"Error: failed to decode JSON frim the file '{file_path}'\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01d0b954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert Unix timestamp to local time\n",
    "def convert_to_local_time(timestamp, offset):\n",
    "    utc_time = datetime.utcfromtimestamp(timestamp)\n",
    "    return utc_time + timedelta(seconds=offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6ad259",
   "metadata": {},
   "source": [
    "processing & cleaning the weather data & storing in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d7cefc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(weather_data):\n",
    "    # Initialize an empty list to store records\n",
    "    data = []\n",
    "\n",
    "    # Process each record\n",
    "    for record in weather_data:\n",
    "        latitude, longitude = record[\"lat\"], record[\"lon\"]\n",
    "        timezone = record[\"timezone\"]\n",
    "        timezone_offset = record[\"timezone_offset\"]\n",
    "        city = record['City']\n",
    "\n",
    "        # Convert timestamps\n",
    "        current_time = convert_to_local_time(record[\"current\"][\"dt\"], timezone_offset)\n",
    "        sunrise = convert_to_local_time(record[\"current\"][\"sunrise\"], timezone_offset)\n",
    "        sunset = convert_to_local_time(record[\"current\"][\"sunset\"], timezone_offset)\n",
    "\n",
    "        # Extract weather details\n",
    "        temp = record[\"current\"][\"temp\"]\n",
    "        feels_like = record[\"current\"][\"feels_like\"]\n",
    "        pressure = record[\"current\"][\"pressure\"]\n",
    "        humidity = record[\"current\"][\"humidity\"]\n",
    "        dew_point = record[\"current\"][\"dew_point\"]\n",
    "        uvi = record[\"current\"][\"uvi\"]\n",
    "        clouds = record[\"current\"][\"clouds\"]\n",
    "        visibility = record[\"current\"][\"visibility\"]\n",
    "        wind_speed = record[\"current\"][\"wind_speed\"]\n",
    "        wind_deg = record[\"current\"][\"wind_deg\"]\n",
    "        wind_gust = record[\"current\"].get(\"wind_gust\", 0)\n",
    "        weather = record[\"current\"][\"weather\"][0]\n",
    "        weather_id = weather[\"id\"]\n",
    "        weather_main = weather[\"main\"]\n",
    "        weather_description = weather[\"description\"]\n",
    "\n",
    "        # Handle alerts (if any)\n",
    "        alerts = record.get(\"alerts\", [])\n",
    "        alert_messages = \"; \".join([alert[\"event\"] + \": \" + alert[\"description\"] for alert in alerts])\n",
    "\n",
    "        # Add the record to the data list\n",
    "        data.append({\n",
    "            \"latitude\": latitude,\n",
    "            \"longitude\": longitude,\n",
    "            \"timezone\": timezone,\n",
    "            \"timezone_offset\": timezone_offset,\n",
    "            \"city\": city,\n",
    "            \"current_time\": current_time,\n",
    "            \"sunrise\": sunrise,\n",
    "            \"sunset\": sunset,\n",
    "            \"temp_F\": temp,\n",
    "            \"feels_like_F\": feels_like,\n",
    "            \"humidity\": humidity,\n",
    "            \"dew_point\": dew_point,\n",
    "            \"uvi\": uvi,\n",
    "            \"clouds\": clouds,\n",
    "            \"visibility\": visibility,\n",
    "            \"wind_speed_mph\": wind_speed,\n",
    "            \"wind_deg\": wind_deg,\n",
    "            \"wind_gust_mph\": wind_gust,\n",
    "            \"weather_id\": weather_id,\n",
    "            \"weather_main\": weather_main,\n",
    "            \"weather_description\": weather_description,\n",
    "            \"alerts\": alert_messages\n",
    "        })\n",
    "\n",
    "    # Create a DataFrame from the data list\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce88281e",
   "metadata": {},
   "source": [
    "writing the cleaned data to the compiled clean_weather_data.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30af317d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to data/clean_weather_data.csv\n"
     ]
    }
   ],
   "source": [
    "def write_to_cleaned_data(df):\n",
    "    # File path within the \"data\" folder\n",
    "    file_path = 'data/clean_weather_data.csv'\n",
    "\n",
    "    # Check if the file exists to decide whether to append or create new\n",
    "    if os.path.exists(file_path):\n",
    "        # If the file exists, load the existing data, then append new data\n",
    "        existing_data = pd.read_csv(file_path)\n",
    "        updated_data = pd.concat([existing_data, df], ignore_index=True)\n",
    "\n",
    "        # Append to the file\n",
    "        updated_data.to_csv(file_path, index=False)\n",
    "    else:\n",
    "        # If the file doesn't exist, create it and write the new data\n",
    "        df.to_csv(file_path, index=False)\n",
    "\n",
    "    print(f\"Data saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7f06d0",
   "metadata": {},
   "source": [
    "writing the cleaned data to the db_ready_data.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baddd667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to data/db_ready_data.csv\n"
     ]
    }
   ],
   "source": [
    "def write_to_db_ready(df):\n",
    "    # File path within the \"data\" folder\n",
    "    file_path = 'data/db_ready_data.csv'\n",
    "\n",
    "    # Check if the file exists to decide whether to append or create new\n",
    "    if os.path.exists(file_path):\n",
    "        # If the file exists, load the existing data, then append new data\n",
    "        existing_data = pd.read_csv(file_path)\n",
    "        updated_data = pd.concat([existing_data, df], ignore_index=True)\n",
    "\n",
    "        # Append to the file\n",
    "        updated_data.to_csv(file_path, index=False)\n",
    "    else:\n",
    "        # If the file doesn't exist, create it and write the new data\n",
    "        df.to_csv(file_path, index=False)\n",
    "\n",
    "    print(f\"Data saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50e5663",
   "metadata": {},
   "source": [
    "execution of the transformation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a98d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_raw_data()\n",
    "df = transform_data(data)\n",
    "write_to_clean_data(df)\n",
    "write_to_db_ready(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c48b47",
   "metadata": {},
   "source": [
    "# Load:\n",
    "write the cleaned data to a postgresql database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eeeabe",
   "metadata": {},
   "source": [
    "function to read the db_read data file and return a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12b8188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_db_ready():\n",
    "    ## open and read each row of the csv file \n",
    "    file_path = 'data/db_ready_data.csv'\n",
    "\n",
    "    df_db = pd.read_csv(file_path)\n",
    "    return df_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaf1274",
   "metadata": {},
   "source": [
    "function to load env variables & establish database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c99ee93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_db_connection()\n",
    "    ## load environment variables and establish database connection\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    ## get local database credentials\n",
    "    DB_NAME = os.getenv(\"DB_NAME\")\n",
    "    DB_USER = os.getenv(\"DB_USER\")\n",
    "    DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "    DB_HOST = os.getenv(\"DB_HOST\")\n",
    "    DB_PORT = os.getenv(\"DB_PORT\")\n",
    "\n",
    "\n",
    "    def connect_db():\n",
    "        try:\n",
    "            conn = psycopg2.connect(\n",
    "                dbname=DB_NAME,\n",
    "                user=DB_USER,\n",
    "                password=DB_PASSWORD,\n",
    "                host=DB_HOST,\n",
    "                port=DB_PORT)\n",
    "            print(\"connected to postgresql on local host\")\n",
    "            return conn\n",
    "        except psycopg2.Error as e:\n",
    "            print(\"connection error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69808664",
   "metadata": {},
   "source": [
    "function to insert weather data into the location database table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e937064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert or get Location_ID\n",
    "def get_or_insert_location(cursor, lat, lon, city, timezone, tz_offset):\n",
    "    cursor.execute(\n",
    "        \"SELECT Location_ID FROM Locations WHERE Lat=%s AND Long=%s;\",\n",
    "        (latitude, longitude)\n",
    "    )\n",
    "    location = cursor.fetchone()\n",
    "    if location:\n",
    "        print(\"location is already stored in the database\")\n",
    "        return location[0]\n",
    "    else:\n",
    "        cursor.execute(\n",
    "            \"INSERT INTO Locations (Lat, Long, City, Timezone, Timezone_offset) VALUES (%s, %s, %s, %s, %s) RETURNING Location_ID;\",\n",
    "            (lat, lon, city, timezone, tz_offset)\n",
    "        )\n",
    "        return cursor.fetchone()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572c7c7f",
   "metadata": {},
   "source": [
    "function to insert weather data into the weather database table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51159dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert or get Weather_ID\n",
    "def get_or_insert_weather(cursor, weather_id, main, description):\n",
    "    cursor.execute(\n",
    "        \"SELECT Weather_ID FROM Weather where Weather_ID=%s;\",\n",
    "        (weather_id,)\n",
    "    )\n",
    "    weather = cursor.fetchone()\n",
    "    if weather:\n",
    "        print(\"weather is already stored in the database\")\n",
    "        return weather[0]\n",
    "    else:\n",
    "        cursor.execute(\n",
    "            \"INSERT INTO Weather (Weather_ID, Main, Description) VALUES (%s, %s, %s) RETURNING Weather_ID;\",\n",
    "            (weather_id, main, description)\n",
    "        )\n",
    "        return cursor.fetchone()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bbf728",
   "metadata": {},
   "source": [
    "function to insert weather data into the record database table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88cd46ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Record\n",
    "\n",
    "def insert_record(cursor, location_id, weather_id, row):\n",
    "    cursor.execute(\n",
    "    \"\"\"\n",
    "    INSERT INTO Records (Location_ID, Weather_ID, Local_time, Sunrise, Sunset, Temp_F, Feels_like_F, \n",
    "                        Humidity, Dew_Point, UVI, Clouds, Visibility, Wind_speed_mph, Wind_deg, Wind_gust_mph)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s) RETURNING Record_ID;\n",
    "    \"\"\",\n",
    "    (location_id, weather_id, row['current_time'], row['sunrise'], row['sunset'], row['temp_F'],\n",
    "        row['feels_like_F'], row['humidity'], row['dew_point'], row['uvi'], row['clouds'], row['visibility'], \n",
    "        row['wind_speed_mph'], row['wind_deg'], row['wind_gust_mph'])\n",
    "    )\n",
    "    print(\"record has been inserted into the table\")\n",
    "    return cursor.fetchone()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1263436",
   "metadata": {},
   "source": [
    "function to insert weather data into the alert database table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d46f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Alert\n",
    "def insert_alert(cursor, record_id, alert_description):\n",
    "    cursor.execute(\n",
    "        \"INSERT INTO Alerts (Record_ID, Description) VALUES (%s, %s);\",\n",
    "        (record_id, alert_description)\n",
    "    )\n",
    "    print(\"alert has been inserted into the table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a017b7cf",
   "metadata": {},
   "source": [
    "function to delete the db_ready csv file once the data has been uploaded to avoid duplication of data loading/records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8009a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_db_ready_file():\n",
    "    ## delete the file\n",
    "    file_path = 'data/db_ready_data.csv'\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "        print(\"File deleted successfully\")\n",
    "    else:\n",
    "        print(\"File does not exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1784f01e",
   "metadata": {},
   "source": [
    "execution of functions above and the load process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "30802ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected to postgresql on local host\n",
      "location is already stored in the database\n",
      "weather is already stored in the database\n",
      "record has been inserted into the table\n",
      "location is already stored in the database\n",
      "weather is already stored in the database\n",
      "record has been inserted into the table\n",
      "alert has been inserted into the table\n",
      "location is already stored in the database\n",
      "weather is already stored in the database\n",
      "record has been inserted into the table\n",
      "alert has been inserted into the table\n",
      "data inserted successfully\n"
     ]
    }
   ],
   "source": [
    "df = read_db_ready()\n",
    "conn = env_db_connection()\n",
    "conn = connect_db()\n",
    "\n",
    "with conn.cursor() as cursor:\n",
    "    for _, row in df_db.iterrows():\n",
    "        location_id = get_or_insert_location(cursor, row['latitude'], row['longitude'], row['city'], row['timezone'], row['timezone_offset'])\n",
    "        weather_id = get_or_insert_weather(cursor, row['weather_id'], row['weather_main'], row['weather_description'])\n",
    "        record_id = insert_record(cursor, location_id, weather_id, row)\n",
    "        \n",
    "        if pd.notna(row['alerts']) and row['alerts'].strip():\n",
    "            insert_alert(cursor, record_id, row['alerts'])\n",
    "    conn.commit()\n",
    "conn.close()\n",
    "print(\"data inserted successfully & connection closed\")\n",
    "delete_db_ready_file()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
